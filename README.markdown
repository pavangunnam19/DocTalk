# **DocTalk \- PDF Question Answering Application**

DocTalk is a Streamlit-based web application that allows users to upload a PDF document and ask questions about its content. The app extracts text from the PDF, generates embeddings using a SentenceTransformer model, and uses Google's Gemini API to provide answers based on the document's content.

## **Features**

* Upload PDF files and extract text content.  
* Ask questions about the PDF and receive answers generated by the Gemini model.  
* Displays chat history for the last 5 interactions.  
* Responsive UI with custom CSS styling.

## **Requirements**

To run DocTalk, you need the following:

### **Software**

* **Python**: Version 3.7 or higher (3.9â€“3.11 recommended).  
* **Operating System**: Windows, macOS, or Linux.  
* **Internet Connection**: Required for downloading the SentenceTransformer model and making Gemini API calls.

### **Hardware**

* **CPU**: Modern multi-core CPU (e.g., Intel i3/i5/i7, AMD Ryzen).  
* **RAM**: Minimum 4GB (8GB or more recommended for large PDFs).  
* **Storage**: \~1GB free space for Python, libraries, and the SentenceTransformer model.

### **Python Packages**

Install the required packages using the following command:

pip install streamlit PyPDF2 sentence-transformers scikit-learn numpy langchain-google-genai python-dotenv

* streamlit: For the web interface.  
* PyPDF2: For PDF text extraction.  
* sentence-transformers: For generating text embeddings (all-MiniLM-L6-v2 model).  
* scikit-learn: For similarity search with NearestNeighbors.  
* numpy: For numerical operations.  
* langchain-google-genai: For integrating with Google's Gemini API.  
* python-dotenv: For managing API keys securely (optional, recommended).

### **Google API Key**

* Obtain a Google API key for the Gemini model (gemini-1.5-flash) from [Google Cloud Console](https://console.cloud.google.com/).  
* Replace YOUR\_ACTUAL\_GOOGLE\_API\_KEY\_HERE in the code with your API key.  
* **Recommended**: Store the API key in a .env file using python-dotenv:  
  GOOGLE\_API\_KEY=your-api-key-here

  Update the code to load the key:  
  from dotenv import load\_dotenv  
  import os  
  load\_dotenv()  
  google\_api\_key \= os.getenv("GOOGLE\_API\_KEY")

## **Installation**

1. **Clone or Download the Code**:  
   * Save the code in a file named app.py.  
2. **Set Up a Virtual Environment** (recommended):  
   python \-m venv venv  
   source venv/bin/activate  \# On Windows: venv\\Scripts\\activate

3. **Install Dependencies**:  
   pip install streamlit PyPDF2 sentence-transformers scikit-learn numpy langchain-google-genai python-dotenv

4. **Configure the API Key**:  
   * Replace the placeholder API key in app.py with your Google API key or use a .env file as described above.  
5. **Run the Application**:  
   streamlit run app.py

   * Access the app at http://localhost:8501 in your browser.

## **Usage**

1. **Upload a PDF**:  
   * Use the file uploader to select a PDF file.  
   * The app processes the PDF and extracts text, which may take a moment for large files.  
2. **Ask Questions**:  
   * Once the PDF is processed, enter your question in the text input field.  
   * The app uses embeddings to find relevant text and generates an answer using the Gemini API.  
3. **View Chat History**:  
   * The last 5 question-answer pairs are displayed below the input field.

## **Troubleshooting**

* **PDF Extraction Issues**: Ensure the PDF contains extractable text. Scanned PDFs may require OCR tools (not supported in this version).  
* **API Key Errors**: Verify that the Google API key is valid and correctly configured.  
* **ModuleNotFoundError**: Ensure all packages are installed in the active Python environment (pip list to verify).  
* **Performance**: For large PDFs, processing may be slow. Consider using a more powerful machine or optimizing text chunking.

## **V2: Advanced Version \- Codex Historica**

This project served as the foundation for [**Codex Historica**](https://www.google.com/search?q=https://github.com/pavangunnam19/Codex-Historica), a more advanced, professional-grade version.

Codex Historica includes a full OCR engine to handle scanned documents, runs a powerful local language model (Google's FLAN-T5), and features a custom-built, industry-standard UI with a FastAPI backend. It represents the next step in building a robust, self-contained AI application.

## **Notes**

* The SentenceTransformer model (all-MiniLM-L6-v2) is downloaded automatically on first use (\~200MB).  
* The app creates a data directory to store temporary PDF files. Ensure write permissions in the app's directory.  
* For production, avoid hardcoding the API key and use environment variables or Streamlit Secrets.

## **Author**

Developed by Pavan Gunnam
